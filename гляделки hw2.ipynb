{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRBhMZtdf94"
      },
      "source": [
        "# Download dataset with Pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNE5Qqw_rdsV"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKAZ-aQtrg8q",
        "outputId": "524ef476-97e6-46a7-8fa2-269f6427bc30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Define transformation for each image\n",
        "transform = transforms.Compose([\n",
        "  transforms.Lambda(lambda x: np.array(x).flatten()), #Stretch image into row [32,32,3] -> [3072]\n",
        "])\n",
        "\n",
        "# Download a CIFAR10 dataset\n",
        "dataset = datasets.CIFAR10(\"content\", train=True, transform=transform, download=True)\n",
        "classes = ['Самолет', 'Автомобиль', 'Птица', 'Кошка', 'Олень', 'Собака', 'Лягушка', 'Лошадь', 'Корабль', 'Грузовик']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3F4IoDErlcw"
      },
      "source": [
        "## Split dataset & define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "Fu02DmABYxoh",
        "outputId": "e49f2b3d-f2bb-4a49-ece7-8d0ec4aa4e3f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Собака'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_ds, val_ds, _= random_split(dataset, [20000, 1000, 29000])\n",
        "# Hint: Perform debug on smaller subset\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
        "\n",
        "# Display one image\n",
        "for images, class_nums in train_loader:\n",
        "  display(Image.fromarray(images[0].reshape((32,32,3)).numpy()), classes[class_nums[0].item()]) \n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqC6xXhSeUPr"
      },
      "source": [
        "# Implement LinearClassifier class for CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "vaxIJUM7eQUp"
      },
      "outputs": [],
      "source": [
        "class LinearClassifier:\n",
        "  def __init__(self, labels, delta=1.6, learning_rate=1e-8, reg_coef=1):\n",
        "    self.labels = labels\n",
        "    self.classes_num = len(labels)\n",
        "    # Generate a random weight matrix of small numbers\n",
        "    # You can change this code\n",
        "    self.W = None\n",
        "    self.delta = delta\n",
        "    self.learning_rate = learning_rate\n",
        "    self.reg_coef = reg_coef\n",
        "  \n",
        "  def train(self, x_batch, y_batch, learning_rate=None):\n",
        "    \"\"\"\n",
        "      Arguments:\n",
        "        x (numpy.array): collection of objects (batch)\n",
        "        y (numpy.array): collection of integer \n",
        "        representing a class number for objects from x\n",
        "    \"\"\"\n",
        "    x_batch = self.add_ones(x_batch)\n",
        "\n",
        "    if self.W is None:\n",
        "      self.W = np.random.randn(x_batch.shape[1], self.classes_num) * 0.0001\n",
        "    if learning_rate is None:\n",
        "      learning_rate = self.learning_rate\n",
        "\n",
        "    loss_val, grad = self.loss(x_batch, y_batch)\n",
        "    self.W -= (grad * learning_rate)\n",
        "    return loss_val\n",
        "\n",
        "  def loss(self, x, y):\n",
        "    \"\"\"\n",
        "      Arguments:\n",
        "        x (numpy.array): collection of objects (batch)\n",
        "        y (numpy.array): collection of integer \n",
        "        representing a class number for objects from x\n",
        "    \"\"\"\n",
        "\n",
        "    size = x.shape[0]\n",
        "\n",
        "    # multiclass SVM loss\n",
        "    predicted = x.dot(self.W)\n",
        "    original = predicted[np.arange(size), y].reshape((size, -1))\n",
        "    losses = np.maximum(0, predicted - original + self.delta)\n",
        "    losses[np.arange(size), y] = 0\n",
        "    loss = np.sum(losses) / size\n",
        "\n",
        "    # gradients\n",
        "    mask = (losses > 0)*1\n",
        "    mask[np.arange(size), y] = -np.sum(mask, axis=1)\n",
        "    dW = np.dot(x.T, mask) / size\n",
        "\n",
        "    # regularization \n",
        "    w = self.W[:-1,:]\n",
        "    loss += self.reg_coef * np.sum(w * w)\n",
        "    biases = self.W[-1, :]\n",
        "    dW += 2 * self.reg_coef * self.W\n",
        "    dW[-1, :] = biases\n",
        "    return loss, dW\n",
        "\n",
        "  def add_ones(self, x):\n",
        "    return np.hstack([x, np.ones((x.shape[0], 1))])\n",
        "\n",
        "  def predict(self, x):\n",
        "    x = self.add_ones(x)\n",
        "    scores = x.dot(self.W) # (256, 3073) * (3073, 10)\n",
        "    return np.argmax(scores, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyVPgrr5xjhU"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5zVN1kHd43W"
      },
      "source": [
        "## Function for accuracy checking\n",
        "\n",
        "Don't change this code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "dzhRClCsdzJw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def validate(model, dataloader):\n",
        "  y_predicted = np.array([])\n",
        "  y_gtrue = np.array([])\n",
        "  for images, class_nums in dataloader:\n",
        "    index = model.predict(images.numpy())\n",
        "    y_predicted = np.append(y_predicted, index) \n",
        "    y_gtrue = np.append(y_gtrue, class_nums.numpy()) \n",
        "  return accuracy_score(y_gtrue, y_predicted)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQr1qYUlxq7X"
      },
      "source": [
        "## Train loop\n",
        "Let's train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "phcDEj7OdpGS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Loss: 6.96687, Accuracy: 0.184\n",
            "Epoch 1 Loss: 6.31238, Accuracy: 0.227\n",
            "Epoch 2 Loss: 5.99735, Accuracy: 0.261\n",
            "Epoch 3 Loss: 5.77201, Accuracy: 0.277\n",
            "Epoch 4 Loss: 5.63550, Accuracy: 0.285\n",
            "Epoch 5 Loss: 5.49337, Accuracy: 0.295\n",
            "Epoch 6 Loss: 5.37729, Accuracy: 0.304\n",
            "Epoch 7 Loss: 5.28684, Accuracy: 0.31\n",
            "Epoch 8 Loss: 5.22864, Accuracy: 0.321\n",
            "Epoch 9 Loss: 5.16961, Accuracy: 0.323\n",
            "Epoch 10 Loss: 5.12319, Accuracy: 0.322\n",
            "Epoch 11 Loss: 5.07534, Accuracy: 0.324\n",
            "Epoch 12 Loss: 5.04426, Accuracy: 0.331\n",
            "Epoch 13 Loss: 5.01517, Accuracy: 0.333\n",
            "Epoch 14 Loss: 4.98465, Accuracy: 0.329\n",
            "Epoch 15 Loss: 4.95782, Accuracy: 0.334\n",
            "Epoch 16 Loss: 4.93390, Accuracy: 0.335\n",
            "Epoch 17 Loss: 4.91683, Accuracy: 0.338\n",
            "Epoch 18 Loss: 4.89474, Accuracy: 0.336\n",
            "Epoch 19 Loss: 4.87456, Accuracy: 0.338\n",
            "Epoch 20 Loss: 4.85135, Accuracy: 0.34\n",
            "Epoch 21 Loss: 4.82563, Accuracy: 0.338\n",
            "Epoch 22 Loss: 4.80498, Accuracy: 0.34\n",
            "Epoch 23 Loss: 4.78788, Accuracy: 0.343\n",
            "Epoch 24 Loss: 4.76717, Accuracy: 0.344\n",
            "Epoch 25 Loss: 4.74980, Accuracy: 0.343\n",
            "Epoch 26 Loss: 4.72850, Accuracy: 0.349\n",
            "Epoch 27 Loss: 4.70992, Accuracy: 0.347\n",
            "Epoch 28 Loss: 4.69583, Accuracy: 0.353\n",
            "Epoch 29 Loss: 4.67726, Accuracy: 0.352\n",
            "Epoch 30 Loss: 4.65757, Accuracy: 0.353\n",
            "Epoch 31 Loss: 4.64003, Accuracy: 0.352\n",
            "Epoch 32 Loss: 4.62424, Accuracy: 0.358\n",
            "Epoch 33 Loss: 4.60481, Accuracy: 0.359\n",
            "Epoch 34 Loss: 4.58959, Accuracy: 0.358\n",
            "Epoch 35 Loss: 4.56990, Accuracy: 0.361\n",
            "Epoch 36 Loss: 4.55444, Accuracy: 0.359\n",
            "Epoch 37 Loss: 4.53774, Accuracy: 0.363\n",
            "Epoch 38 Loss: 4.52431, Accuracy: 0.363\n",
            "Epoch 39 Loss: 4.50648, Accuracy: 0.366\n",
            "Epoch 40 Loss: 4.48894, Accuracy: 0.365\n",
            "Epoch 41 Loss: 4.47195, Accuracy: 0.366\n",
            "Epoch 42 Loss: 4.45349, Accuracy: 0.365\n",
            "Epoch 43 Loss: 4.43403, Accuracy: 0.368\n",
            "Epoch 44 Loss: 4.41796, Accuracy: 0.368\n",
            "Epoch 45 Loss: 4.40416, Accuracy: 0.37\n",
            "Epoch 46 Loss: 4.38580, Accuracy: 0.37\n",
            "Epoch 47 Loss: 4.37011, Accuracy: 0.371\n",
            "Epoch 48 Loss: 4.35628, Accuracy: 0.37\n",
            "Epoch 49 Loss: 4.34306, Accuracy: 0.371\n",
            "Best accuracy is 0.371\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(122)\n",
        "model = LinearClassifier(dataset.classes, delta=1, reg_coef=100)\n",
        "best_accuracy = 0\n",
        "for epoch in range(50):\n",
        "  for images, class_nums in train_loader:\n",
        "    loss = model.train(images.numpy(), class_nums.numpy())\n",
        "    accuracy = validate(model, val_loader)\n",
        "    \n",
        "  best_accuracy = max(best_accuracy, accuracy)\n",
        "  print(f\"Epoch {epoch} Loss: {loss:.5f}, Accuracy: {accuracy}\")\n",
        "\n",
        "print(f\"Best accuracy is {best_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4tIFR5bwZFi"
      },
      "source": [
        "# Check model on test dataset\n",
        "\n",
        "You must get accuracy above 0.35\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "MM0pWYJlwibm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Accuracy on test: 0.3664\n"
          ]
        }
      ],
      "source": [
        "test_dataset = datasets.CIFAR10(\"content\", train=False, transform=transform, download=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
        "\n",
        "accuracy = validate(model, test_loader)\n",
        "print(f\"Accuracy on test: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsImxpggG8bH"
      },
      "source": [
        "# Place for brief conclusion\n",
        "Feel free to describe troubles here.\n",
        "\n",
        "\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ13OmfCEb1w"
      },
      "source": [
        "# Ideas for extra work\n",
        "\n",
        "- Implenment CrossEntropyLoss function\n",
        "- Implement bias trick ✅\n",
        "- Add regularization to SVM loss ✅\n",
        "- Find best learning rate and regularization strength using Cross-Validation\n",
        "- Normalize data "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
