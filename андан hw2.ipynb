{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSE 2021: Mathematical Methods for Data Analysis\n",
    "\n",
    "## Homework 2\n",
    "\n",
    "### Attention!\n",
    "* For tasks where <ins>text answer</ins> is required **Russian language** is **allowed**.\n",
    "* If a task asks you to describe something (make coclusions) then **text answer** is **mandatory** and **is** part of the task\n",
    "* We **only** accept **ipynb** notebooks. If you use Google Colab then you'll have to download the notebook before passing the homework\n",
    "* **Do not** use python loops instead of NumPy vector operations over NumPy vectors - it significantly decreases performance (see why https://blog.paperspace.com/numpy-optimization-vectorization-and-broadcasting/), will be punished with -0.25 for **every** task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T16:48:20.566549Z",
     "start_time": "2020-09-26T16:48:19.893995Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "For this homework we use Boston Dataset from sklearn (based on UCI ML housing dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston() # load dataset\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "columns = data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [0.5 points] \n",
    "Create Pandas DataFrame and split the data into train and test sets with ratio 80:20 with random_state=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=columns)\n",
    "df['target'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. [1 point] \n",
    "Train models on train data using StatsModels( or sckit-learn) library and apply it to the test set; use $RMSE$ and $R^2$ as the quality measure.\n",
    "\n",
    "* [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html);\n",
    "* [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) with $\\alpha = 0.01$;\n",
    "* [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) with $\\alpha = 0.01$\n",
    "\n",
    "Don't forget to scale the data before training the models with StandardScaler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression RMSE 5.78351 R² 0.58922\n",
      "Ridge            RMSE 5.78361 R² 0.58921\n",
      "Lasso            RMSE 5.79609 R² 0.58743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def add_constant(arr):\n",
    "    return np.c_[arr, np.ones((arr.shape[0], 1))]\n",
    "\n",
    "scaler = StandardScaler().fit(train[columns])\n",
    "trainX, testX = scaler.transform(train[columns]), scaler.transform(test[columns])\n",
    "trainY, testY = train['target'], test['target']\n",
    "trainXc = add_constant(trainX)\n",
    "testXс = add_constant(testX)\n",
    "\n",
    "models = {}\n",
    "def run_model(model):\n",
    "    name = type(model).__name__\n",
    "    models[name] = reg = model.fit(trainXc, trainY)\n",
    "    prediction = reg.predict(testXс)\n",
    "    rmse = mean_squared_error(testY, prediction, squared=False)\n",
    "    r2 = r2_score(testY, prediction)\n",
    "    print(f\"{name: <16} RMSE {rmse:.5f} R² {r2:.5f}\")\n",
    "    return reg\n",
    "\n",
    "run_model(LinearRegression(fit_intercept=False))\n",
    "run_model(Ridge(0.01, fit_intercept=False))\n",
    "run_model(Lasso(0.01, fit_intercept=False))\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3. [1 point] \n",
    "Explore the values of the parameters of the resulting models and compare the number of zero weights in them. \n",
    "\n",
    "Comment on the significance of the coefficients, overal model significance and other related factors from the results table. \n",
    "\n",
    "`Hint` Use StatModels to obtain significance of the coefficients. They ca be found on the `summary` of the fitted linear model. \n",
    "It might be tricky to obtain `summary` for the regularized model. Please, read the documentation of the StatModels library to figure out how to do that, e.g.   [OLSResults](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.html#statsmodels.regression.linear_model.OLSResults) class might be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.97082019  1.05714873  0.03831099  0.59450642 -1.8551476   2.57321942\n",
      " -0.08761547 -2.88094259  2.11224542 -1.87533131 -2.29276735  0.71817947\n",
      " -3.59245482 22.61188119]\n",
      "[-0.97073209  1.05698134  0.03803375  0.59455017 -1.85478991  2.57332859\n",
      " -0.08769363 -2.88061155  2.11145769 -1.87461001 -2.29266974  0.71818063\n",
      " -3.59228891 22.6113215 ]\n",
      "[-0.93978318  1.02379427 -0.          0.59493689 -1.80527062  2.58451328\n",
      " -0.06803866 -2.81157046  1.9540071  -1.73716215 -2.27791791  0.70474855\n",
      " -3.59775918 22.60188119]\n"
     ]
    }
   ],
   "source": [
    "print(models['LinearRegression'].coef_)\n",
    "print(models['Ridge'].coef_)\n",
    "print(models['Lasso'].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ровные нули у нас есть только в модели Lasso, потому что в этом весь её смысл: она выбрасывает достаточно маленькие значения и заменяет их на нули.\n",
    "Ноль получился только один: `x3`, и он самый маленький во всех остальных моделях.\n",
    "Ещё есть `x7`, но он недостаточно маленький, чтобы его Lasso округлил в ноль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>target</td>      <th>  R-squared:         </th> <td>   0.773</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.765</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   102.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Oct 2021</td> <th>  Prob (F-statistic):</th> <td>9.64e-117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:51:55</td>     <th>  Log-Likelihood:    </th> <td> -1171.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   404</td>      <th>  AIC:               </th> <td>   2371.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>   2427.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.9708</td> <td>    0.298</td> <td>   -3.257</td> <td> 0.001</td> <td>   -1.557</td> <td>   -0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.0571</td> <td>    0.341</td> <td>    3.102</td> <td> 0.002</td> <td>    0.387</td> <td>    1.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0383</td> <td>    0.443</td> <td>    0.087</td> <td> 0.931</td> <td>   -0.832</td> <td>    0.909</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.5945</td> <td>    0.229</td> <td>    2.595</td> <td> 0.010</td> <td>    0.144</td> <td>    1.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -1.8551</td> <td>    0.485</td> <td>   -3.828</td> <td> 0.000</td> <td>   -2.808</td> <td>   -0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    2.5732</td> <td>    0.317</td> <td>    8.106</td> <td> 0.000</td> <td>    1.949</td> <td>    3.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0876</td> <td>    0.402</td> <td>   -0.218</td> <td> 0.828</td> <td>   -0.878</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -2.8809</td> <td>    0.445</td> <td>   -6.480</td> <td> 0.000</td> <td>   -3.755</td> <td>   -2.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    2.1122</td> <td>    0.607</td> <td>    3.481</td> <td> 0.001</td> <td>    0.919</td> <td>    3.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -1.8753</td> <td>    0.665</td> <td>   -2.819</td> <td> 0.005</td> <td>   -3.183</td> <td>   -0.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -2.2928</td> <td>    0.300</td> <td>   -7.636</td> <td> 0.000</td> <td>   -2.883</td> <td>   -1.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.7182</td> <td>    0.261</td> <td>    2.749</td> <td> 0.006</td> <td>    0.204</td> <td>    1.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -3.5925</td> <td>    0.395</td> <td>   -9.086</td> <td> 0.000</td> <td>   -4.370</td> <td>   -2.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   22.6119</td> <td>    0.223</td> <td>  101.576</td> <td> 0.000</td> <td>   22.174</td> <td>   23.050</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>141.494</td> <th>  Durbin-Watson:     </th> <td>   1.996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 629.882</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.470</td>  <th>  Prob(JB):          </th> <td>1.67e-137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.365</td>  <th>  Cond. No.          </th> <td>    9.81</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   R-squared:                       0.773\n",
       "Model:                            OLS   Adj. R-squared:                  0.765\n",
       "Method:                 Least Squares   F-statistic:                     102.2\n",
       "Date:                Mon, 11 Oct 2021   Prob (F-statistic):          9.64e-117\n",
       "Time:                        19:51:55   Log-Likelihood:                -1171.5\n",
       "No. Observations:                 404   AIC:                             2371.\n",
       "Df Residuals:                     390   BIC:                             2427.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.9708      0.298     -3.257      0.001      -1.557      -0.385\n",
       "x2             1.0571      0.341      3.102      0.002       0.387       1.727\n",
       "x3             0.0383      0.443      0.087      0.931      -0.832       0.909\n",
       "x4             0.5945      0.229      2.595      0.010       0.144       1.045\n",
       "x5            -1.8551      0.485     -3.828      0.000      -2.808      -0.902\n",
       "x6             2.5732      0.317      8.106      0.000       1.949       3.197\n",
       "x7            -0.0876      0.402     -0.218      0.828      -0.878       0.703\n",
       "x8            -2.8809      0.445     -6.480      0.000      -3.755      -2.007\n",
       "x9             2.1122      0.607      3.481      0.001       0.919       3.305\n",
       "x10           -1.8753      0.665     -2.819      0.005      -3.183      -0.567\n",
       "x11           -2.2928      0.300     -7.636      0.000      -2.883      -1.702\n",
       "x12            0.7182      0.261      2.749      0.006       0.204       1.232\n",
       "x13           -3.5925      0.395     -9.086      0.000      -4.370      -2.815\n",
       "const         22.6119      0.223    101.576      0.000      22.174      23.050\n",
       "==============================================================================\n",
       "Omnibus:                      141.494   Durbin-Watson:                   1.996\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              629.882\n",
       "Skew:                           1.470   Prob(JB):                    1.67e-137\n",
       "Kurtosis:                       8.365   Cond. No.                         9.81\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# чтобы достать significance of the coefficients нужно пересоздать все модели в statsmodels.api\n",
    "import statsmodels.api as sm\n",
    "\n",
    "linreg_model = sm.OLS(trainY, trainXc).fit()\n",
    "ridge_model = sm.OLS(trainY, trainXc).fit_regularized(alpha=0.01, L1_wt=1e-16, refit=True) # c L1_wt=0 не работает 🙁\n",
    "lasso_model = sm.OLS(trainY, trainXc).fit_regularized(alpha=0.01, L1_wt=1, refit=True)\n",
    "\n",
    "linreg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>target</td>      <th>  R-squared:         </th> <td>   0.773</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.765</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   94.87</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Oct 2021</td> <th>  Prob (F-statistic):</th> <td>4.81e-116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:51:55</td>     <th>  Log-Likelihood:    </th> <td> -1171.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   404</td>      <th>  AIC:               </th> <td>   2373.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>   2433.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.9708</td> <td>    0.298</td> <td>   -3.257</td> <td> 0.001</td> <td>   -1.557</td> <td>   -0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.0571</td> <td>    0.341</td> <td>    3.102</td> <td> 0.002</td> <td>    0.387</td> <td>    1.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0383</td> <td>    0.443</td> <td>    0.087</td> <td> 0.931</td> <td>   -0.832</td> <td>    0.909</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.5945</td> <td>    0.229</td> <td>    2.595</td> <td> 0.010</td> <td>    0.144</td> <td>    1.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -1.8551</td> <td>    0.485</td> <td>   -3.828</td> <td> 0.000</td> <td>   -2.808</td> <td>   -0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    2.5732</td> <td>    0.317</td> <td>    8.106</td> <td> 0.000</td> <td>    1.949</td> <td>    3.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0876</td> <td>    0.402</td> <td>   -0.218</td> <td> 0.828</td> <td>   -0.878</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -2.8809</td> <td>    0.445</td> <td>   -6.480</td> <td> 0.000</td> <td>   -3.755</td> <td>   -2.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    2.1122</td> <td>    0.607</td> <td>    3.481</td> <td> 0.001</td> <td>    0.919</td> <td>    3.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -1.8753</td> <td>    0.665</td> <td>   -2.819</td> <td> 0.005</td> <td>   -3.183</td> <td>   -0.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -2.2928</td> <td>    0.300</td> <td>   -7.636</td> <td> 0.000</td> <td>   -2.883</td> <td>   -1.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.7182</td> <td>    0.261</td> <td>    2.749</td> <td> 0.006</td> <td>    0.204</td> <td>    1.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -3.5925</td> <td>    0.395</td> <td>   -9.086</td> <td> 0.000</td> <td>   -4.370</td> <td>   -2.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   22.6119</td> <td>    0.223</td> <td>  101.576</td> <td> 0.000</td> <td>   22.174</td> <td>   23.050</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>141.494</td> <th>  Durbin-Watson:     </th> <td>   1.996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 629.882</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.470</td>  <th>  Prob(JB):          </th> <td>1.67e-137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.365</td>  <th>  Cond. No.          </th> <td>    9.81</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   R-squared:                       0.773\n",
       "Model:                            OLS   Adj. R-squared:                  0.765\n",
       "Method:                 Least Squares   F-statistic:                     94.87\n",
       "Date:                Mon, 11 Oct 2021   Prob (F-statistic):          4.81e-116\n",
       "Time:                        19:51:55   Log-Likelihood:                -1171.5\n",
       "No. Observations:                 404   AIC:                             2373.\n",
       "Df Residuals:                     390   BIC:                             2433.\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.9708      0.298     -3.257      0.001      -1.557      -0.385\n",
       "x2             1.0571      0.341      3.102      0.002       0.387       1.727\n",
       "x3             0.0383      0.443      0.087      0.931      -0.832       0.909\n",
       "x4             0.5945      0.229      2.595      0.010       0.144       1.045\n",
       "x5            -1.8551      0.485     -3.828      0.000      -2.808      -0.902\n",
       "x6             2.5732      0.317      8.106      0.000       1.949       3.197\n",
       "x7            -0.0876      0.402     -0.218      0.828      -0.878       0.703\n",
       "x8            -2.8809      0.445     -6.480      0.000      -3.755      -2.007\n",
       "x9             2.1122      0.607      3.481      0.001       0.919       3.305\n",
       "x10           -1.8753      0.665     -2.819      0.005      -3.183      -0.567\n",
       "x11           -2.2928      0.300     -7.636      0.000      -2.883      -1.702\n",
       "x12            0.7182      0.261      2.749      0.006       0.204       1.232\n",
       "x13           -3.5925      0.395     -9.086      0.000      -4.370      -2.815\n",
       "const         22.6119      0.223    101.576      0.000      22.174      23.050\n",
       "==============================================================================\n",
       "Omnibus:                      141.494   Durbin-Watson:                   1.996\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              629.882\n",
       "Skew:                           1.470   Prob(JB):                    1.67e-137\n",
       "Kurtosis:                       8.365   Cond. No.                         9.81\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>target</td>      <th>  R-squared:         </th> <td>   0.773</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.766</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   102.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Oct 2021</td> <th>  Prob (F-statistic):</th> <td>4.67e-117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:51:55</td>     <th>  Log-Likelihood:    </th> <td> -1171.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   404</td>      <th>  AIC:               </th> <td>   2371.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   2427.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.9718</td> <td>    0.297</td> <td>   -3.267</td> <td> 0.001</td> <td>   -1.557</td> <td>   -0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.0546</td> <td>    0.339</td> <td>    3.110</td> <td> 0.002</td> <td>    0.388</td> <td>    1.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.5963</td> <td>    0.228</td> <td>    2.616</td> <td> 0.009</td> <td>    0.148</td> <td>    1.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -1.8443</td> <td>    0.468</td> <td>   -3.944</td> <td> 0.000</td> <td>   -2.764</td> <td>   -0.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    2.5707</td> <td>    0.316</td> <td>    8.142</td> <td> 0.000</td> <td>    1.950</td> <td>    3.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0883</td> <td>    0.402</td> <td>   -0.220</td> <td> 0.826</td> <td>   -0.878</td> <td>    0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -2.8894</td> <td>    0.433</td> <td>   -6.671</td> <td> 0.000</td> <td>   -3.741</td> <td>   -2.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    2.0956</td> <td>    0.575</td> <td>    3.646</td> <td> 0.000</td> <td>    0.965</td> <td>    3.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -1.8489</td> <td>    0.590</td> <td>   -3.133</td> <td> 0.002</td> <td>   -3.009</td> <td>   -0.689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -2.2887</td> <td>    0.296</td> <td>   -7.728</td> <td> 0.000</td> <td>   -2.871</td> <td>   -1.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.7175</td> <td>    0.261</td> <td>    2.751</td> <td> 0.006</td> <td>    0.205</td> <td>    1.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -3.5898</td> <td>    0.394</td> <td>   -9.118</td> <td> 0.000</td> <td>   -4.364</td> <td>   -2.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   22.6119</td> <td>    0.222</td> <td>  101.706</td> <td> 0.000</td> <td>   22.175</td> <td>   23.049</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>141.572</td> <th>  Durbin-Watson:     </th> <td>   1.997</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 630.874</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.470</td>  <th>  Prob(JB):          </th> <td>1.02e-137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.370</td>  <th>  Cond. No.          </th> <td>    9.81</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   R-squared:                       0.773\n",
       "Model:                            OLS   Adj. R-squared:                  0.766\n",
       "Method:                 Least Squares   F-statistic:                     102.4\n",
       "Date:                Mon, 11 Oct 2021   Prob (F-statistic):          4.67e-117\n",
       "Time:                        19:51:55   Log-Likelihood:                -1171.5\n",
       "No. Observations:                 404   AIC:                             2371.\n",
       "Df Residuals:                     391   BIC:                             2427.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.9718      0.297     -3.267      0.001      -1.557      -0.387\n",
       "x2             1.0546      0.339      3.110      0.002       0.388       1.721\n",
       "x3                  0          0        nan        nan           0           0\n",
       "x4             0.5963      0.228      2.616      0.009       0.148       1.044\n",
       "x5            -1.8443      0.468     -3.944      0.000      -2.764      -0.925\n",
       "x6             2.5707      0.316      8.142      0.000       1.950       3.191\n",
       "x7            -0.0883      0.402     -0.220      0.826      -0.878       0.701\n",
       "x8            -2.8894      0.433     -6.671      0.000      -3.741      -2.038\n",
       "x9             2.0956      0.575      3.646      0.000       0.965       3.226\n",
       "x10           -1.8489      0.590     -3.133      0.002      -3.009      -0.689\n",
       "x11           -2.2887      0.296     -7.728      0.000      -2.871      -1.706\n",
       "x12            0.7175      0.261      2.751      0.006       0.205       1.230\n",
       "x13           -3.5898      0.394     -9.118      0.000      -4.364      -2.816\n",
       "const         22.6119      0.222    101.706      0.000      22.175      23.049\n",
       "==============================================================================\n",
       "Omnibus:                      141.572   Durbin-Watson:                   1.997\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              630.874\n",
       "Skew:                           1.470   Prob(JB):                    1.02e-137\n",
       "Kurtosis:                       8.370   Cond. No.                         9.81\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У `x3` и `x7` самые большие pvalue, значит Lasso правильно сделало что викинуло `x3`. А у всех остальных фич pvalue > 0.05, и поэтому их выкидывать ненадо. Вообще без `x3` и `x7` модели выгледять очень красиво, тк везде pvalue очень маленькие. (❁´◡`❁)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. [1 point] \n",
    "Implement one of the elimination algorithms that were described in the Seminar_4 (Elimination by P-value, Forward elimination, Backward elimination), make conclusions. \n",
    "It's enough to apply to one of the models above (e.g simple linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
      "{'AGE', 'INDUS'}\n"
     ]
    }
   ],
   "source": [
    "def elimination():\n",
    "    cols = list(columns)\n",
    "    mse_dict = {} \n",
    "    while len(cols):\n",
    "        scaler = StandardScaler().fit(train[cols])\n",
    "        trainX, testX = scaler.transform(train[cols]), scaler.transform(test[cols])\n",
    "        trainY, testY = train['target'], test['target']\n",
    "        trainXc, testXс = add_constant(trainX), add_constant(testX)\n",
    "\n",
    "        model = sm.OLS(trainY, trainXc).fit()\n",
    "        mse = mean_squared_error(testY, model.predict(testXс))\n",
    "        mse_dict[mse] = cols[:]\n",
    "        \n",
    "        del cols[model.pvalues.argmax()]\n",
    "    \n",
    "    return mse_dict[min(mse_dict)]\n",
    "\n",
    "cols = elimination()\n",
    "print(cols)\n",
    "print(set(columns) - set(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм элиминации выкинул колонки только `INDUS` и `AGE`, тоесть `x3` и `x7` -- те же самые, у которых были очень большие pvalue, что логично тк алгорит на них и смотрит. Но он остановился в правильном месте, и оставил все остальные колонки. Для этого ему пришлось по одной удалить все колонки, и потом вернутся на то место где был минимальный MSE. Вроде в задание имелось ввиду что нужно останавливатся после первого ухудшения MSE, но тогда у нас неполучится выкинуть даже первую колонку, с которой даже справился Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. [1 point] \n",
    "Find the best (in terms of RMSE) $\\alpha$ for Ridge regression using cross-validation with 5 folds. You must select values from range $[10^{-4}, 10^{3}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 7.196856730011514}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gscv = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 3)}, scoring='neg_root_mean_squared_error', cv=5)\n",
    "gscv.fit(trainXc, trainY)\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Gradient descent\n",
    "\n",
    "#### 6. [3.5 points] \n",
    "**Implement a linear regression model for the MSE loss function, trained by gradient descent.**\n",
    "\n",
    "All calculations must be vectorized, and python loops can only be used for gradient descent iterations. As a stop criterion, you must use (simultaneously):\n",
    "\n",
    "* checking for the Euclidean norm of the weight difference on two adjacent iterations (for example, less than some small number of the order of $10^{-6}$, set by the `tolerance` parameter);\n",
    "* reaching the maximum number of iterations (for example, 10000, set by the `max_iter` parameter).\n",
    "\n",
    "You need to implement:\n",
    "\n",
    "* Full gradient descent:\n",
    "\n",
    "$$\n",
    "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} Q(w_{k}).\n",
    "$$\n",
    "\n",
    "* Stochastic Gradient Descent:\n",
    "\n",
    "$$\n",
    "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} q_{i_{k}}(w_{k}).\n",
    "$$\n",
    "\n",
    "$\\nabla_{w} q_{i_{k}}(w_{k}) \\, $ is the estimate of the gradient over the batch of objects selected randomly.\n",
    "\n",
    "* Momentum method:\n",
    "\n",
    "$$\n",
    "h_0 = 0, \\\\\n",
    "h_{k + 1} = \\alpha h_{k} + \\eta_k \\nabla_{w} q_{i_{k}} (w_{k}), \\\\\n",
    "w_{k + 1} = w_{k} - h_{k + 1}.\n",
    "$$\n",
    "\n",
    "Exponentially weighed averages can provide a better estimate which is closer to the actual gradient.\n",
    "\n",
    "\n",
    "To make sure that the optimization process really converges, we will use the `loss_history` class attribute. After calling the `fit` method, it should contain the values of the loss function for all iterations, starting from the first one (before the first step on the anti-gradient).\n",
    "\n",
    "You need to initialize the weights with a zero or random (from a normal distribution) vector. The following is a template class that needs to contain the code implementing all variations of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from math import floor\n",
    "\n",
    "class LinReg(BaseEstimator):\n",
    "    def __init__(self, delta=0.5, gd_type='Momentum', tolerance=1e-4, max_iter=1000, w0=None, eta=1e-2, alpha=1e-3):\n",
    "        \"\"\"\n",
    "        gd_type: str\n",
    "            'GradientDescent', 'StochasticDescent', 'Momentum'\n",
    "        delta: float\n",
    "            proportion of object in a batch (fot stochastic GD)\n",
    "        tolerance: float\n",
    "            for stopping gradient descent\n",
    "        max_iter: int\n",
    "            maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d)\n",
    "            init weights\n",
    "        eta: float\n",
    "            learning rate\n",
    "        alpha: float\n",
    "            momentum coefficient\n",
    "        \"\"\"\n",
    "        \n",
    "        self.h_prev = 0\n",
    "        self.gd_type = gd_type\n",
    "        self.delta = delta\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.eta = eta\n",
    "        self.loss_history = None # list of loss function values at each training iteration\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        self.loss_history = []\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        if self.w0 is None:\n",
    "            self.w0 = np.zeros(X.shape[1]) # + 1\n",
    "        \n",
    "        self.w = self.w0\n",
    "        self.loss_history.append(self.calc_loss(X, y))\n",
    "        for _ in range(self.max_iter):\n",
    "            gradient = self.calc_gradient(X, y)\n",
    "            if np.linalg.norm(gradient) < self.tolerance:\n",
    "                break\n",
    "            self.w -= gradient\n",
    "            self.loss_history.append(self.calc_loss(X, y))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        \n",
    "        return X @ self.w.T\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d) (l can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.gd_type != 'GradientDescent':\n",
    "            idxs = np.random.randint(0, y.size, floor(self.delta*y.size))\n",
    "            X,y = X[idxs,:],y[idxs]\n",
    "\n",
    "        res = 2/y.size * (self.predict(X) - y).dot(X) * self.eta\n",
    "\n",
    "        if self.gd_type == 'Momentum':\n",
    "            res += self.h_prev * self.alpha\n",
    "            self.h_prev = res\n",
    "\n",
    "        return res\n",
    "\n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: float \n",
    "        \"\"\" \n",
    "        return (np.array(self.predict(X) - y)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. [1 points] \n",
    "Train and validate \"hand-written\" model (simple linear regression) on the same data, and compare the quality with the Sklearn or StatsModels methods. Investigate the effect of the `max_iter` and `alpha` parameters on the optimization process. Is it consistent with your expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression RMSE 5.78351 R² 0.58922\n",
      "LinReg           RMSE 5.80021 R² 0.58685\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "run_model(LinearRegression())\n",
    "run_model(LinReg())\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заместить, `sklearn`-овская модель выдаёт RMSE чуть-чуть меньше чем наша, и $R^2$ чуть-чуть больше.\n",
    "RMSE надо минизировать а $R^2$ максимизировать, то есть наша модель получилась хуже библиотечной, как и следовало ожидать.\n",
    "Но разница метрик неочень большая, что значит что наша модель всётаки работает, хотя и не так хорошо как библиотечная.\n",
    "\n",
    "![ура](https://vk.com/sticker/1-13240-128b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "alphas = [0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.9, 0.99]\n",
    "gscv = GridSearchCV(LinReg(), {'alpha': alphas}, scoring='neg_mean_squared_error')\n",
    "gscv.fit(trainXc, trainY)\n",
    "print(gscv.best_params_)\n",
    "\n",
    "plt.plot(alphas, -gscv.cv_results_[\"mean_test_score\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все значения $\\alpha$ меньше $0.1$, по-видимому, эквивалентны и их эфиктивность случайно меняется каждый раз,\n",
    "когда мы строим график заного с другим рандомным сидом.\n",
    "А для значений больше $0.1$ -- чем ближе они к единице, тем хуже становится их обышка. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 1000}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "max_iters = [1, 5, 10, 20, 50, 100, 200, 500, 1000, 1500]\n",
    "gscv = GridSearchCV(LinReg(), {'max_iter': max_iters}, scoring='neg_mean_squared_error')\n",
    "gscv.fit(trainXc, trainY)\n",
    "print(gscv.best_params_)\n",
    "\n",
    "plt.plot(max_iters, -gscv.cv_results_[\"mean_test_score\"])\n",
    "plt.ylim(20, 35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значния `max_iter` меньше 200 дают ужасные результаты, а после 500та нету ощутимых улучшений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. [1 points] \n",
    "Plot graphs (on the same picture) of the dependence of the loss function value on the iteration number for Full GD, SGD and Momentum. Draw conclusions about the rate of convergence of various modifications of gradient descent.\n",
    "\n",
    "Don't forget about what *beautiful* graphics should look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinReg           RMSE 5.88944 R² 0.57404\n",
      "LinReg           RMSE 6.14469 R² 0.53631\n",
      "LinReg           RMSE 5.89860 R² 0.57271\n",
      "LinReg           RMSE 5.93354 R² 0.56763\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "prams = dict(delta=0.1, max_iter=500)\n",
    "gd = run_model(LinReg(gd_type='GradientDescent', **prams))\n",
    "sgd = run_model(LinReg(gd_type='StochasticDescent', **prams))\n",
    "msgd1 = run_model(LinReg(gd_type='Momentum', **prams, alpha=0.1))\n",
    "msgd5 = run_model(LinReg(gd_type='Momentum', **prams, alpha=0.5))\n",
    "\n",
    "x = np.array(range(len(gd.loss_history)))\n",
    "plt.plot(x, gd.loss_history, label=\"GradientDescent\")\n",
    "plt.plot(x, sgd.loss_history, label=\"StochasticDescent\")\n",
    "plt.plot(x, msgd1.loss_history, label=r\"Momentum $\\alpha = 0.1$\")\n",
    "plt.plot(x, msgd5.loss_history, label=r\"Momentum $\\alpha = 0.5$\")\n",
    "plt.ylim(18, 30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моментум, особенно с большой $\\alpha$, очень быстро находит относительно адекватное значение, но потом рандомно колеблется около оптимального значения, но, в отличие от `StochasticDescent`-а, в конце концов в него поподает.\n",
    "Только обычный `GradientDescent` вообще кудато сходится, все остальные просто колеблятся."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f23faf4bfe871c203c8bec80520af5927fc7cb1ae3bd834ddf554ee587ad1c05"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
